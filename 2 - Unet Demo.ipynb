{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet.unet_model import UnetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import transforms\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training U-Net models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, resolution, which_challenge, use_seed=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_func (common.subsample.MaskFunc): A function that can create a mask of\n",
    "                appropriate shape.\n",
    "            resolution (int): Resolution of the image.\n",
    "            which_challenge (str): Either \"singlecoil\" or \"multicoil\" denoting the dataset.\n",
    "            use_seed (bool): If true, this class computes a pseudo random number generator seed\n",
    "                from the filename. This ensures that the same mask is used for all the slices of\n",
    "                a given volume every time.\n",
    "        \"\"\"\n",
    "        if which_challenge not in ('singlecoil', 'multicoil'):\n",
    "            raise ValueError(f'Challenge should either be \"singlecoil\" or \"multicoil\"')\n",
    "        self.mask_func = mask_func\n",
    "        self.resolution = resolution\n",
    "        self.which_challenge = which_challenge\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __call__(self, kspace, target, attrs, fname, slice):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kspace (numpy.array): Input k-space of shape (num_coils, rows, cols, 2) for multi-coil\n",
    "                data or (rows, cols, 2) for single coil data.\n",
    "            target (numpy.array): Target image\n",
    "            attrs (dict): Acquisition related information stored in the HDF5 object.\n",
    "            fname (str): File name\n",
    "            slice (int): Serial number of the slice.\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "                image (torch.Tensor): Zero-filled input image.\n",
    "                target (torch.Tensor): Target image converted to a torch Tensor.\n",
    "                mean (float): Mean value used for normalization.\n",
    "                std (float): Standard deviation value used for normalization.\n",
    "                norm (float): L2 norm of the entire volume.\n",
    "        \"\"\"\n",
    "        target = transforms.to_tensor(target)\n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        # Apply mask\n",
    "        seed = None if not self.use_seed else tuple(map(ord, fname))\n",
    "        masked_kspace, mask = transforms.apply_mask(kspace, self.mask_func, seed)\n",
    "        # Inverse Fourier Transform to get zero filled solution\n",
    "        image = transforms.ifft2(masked_kspace)\n",
    "        # Crop input image to given resolution if larger\n",
    "        smallest_width = min(min(self.resolution, image.shape[-2]), target.shape[-1])\n",
    "        smallest_height = min(min(self.resolution, image.shape[-3]), target.shape[-2])\n",
    "        crop_size = (smallest_height, smallest_width)\n",
    "        image = transforms.complex_center_crop(image, crop_size)\n",
    "        target = transforms.center_crop(target, crop_size)\n",
    "\n",
    "        # Absolute value\n",
    "        image = transforms.complex_abs(image)\n",
    "        # Apply Root-Sum-of-Squares if multicoil data\n",
    "        if self.which_challenge == 'multicoil':\n",
    "            image = transforms.root_sum_of_squares(image)\n",
    "        # Normalize input\n",
    "        image, mean, std = transforms.normalize_instance(image, eps=1e-11)\n",
    "        image = image.clamp(-6, 6)\n",
    "\n",
    "        # Normalize target\n",
    "        target = transforms.normalize(target, mean, std, eps=1e-11)\n",
    "        target = target.clamp(-6, 6)\n",
    "        return image, target, mean, std, attrs['norm'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from common.subsample import create_mask_for_mask_type\n",
    "from data.mri_data import SliceData\n",
    "\n",
    "def create_datasets(data_path,\n",
    "                    mask_type='random',\n",
    "                    center_fractions=[0.08, 0.04],\n",
    "                    accelerations=[4, 8],\n",
    "                    resolution=320,\n",
    "                    challenge='singlecoil',\n",
    "                    sample_rate=1.):\n",
    "    # mask_type: 'random' or 'equispaced'\n",
    "    # center_fractions: Fraction of low-frequency k-space columns to be sampled.\n",
    "    #                   Should have the same length as accelerations\n",
    "    # accelerations: Ratio of k-space columns to be sampled.\n",
    "    #                If multiple values are provided, then one of those is chosen\n",
    "    #                uniformly at random for each volume.\n",
    "    # resolution: Resolution of images\n",
    "    # challenge: 'singlecoil' or 'multicoil'\n",
    "    # sample_rate: Fraction of total volumes to include\n",
    "    train_mask = create_mask_for_mask_type(mask_type, center_fractions, accelerations)\n",
    "    dev_mask = create_mask_for_mask_type(mask_type, center_fractions, accelerations)\n",
    "\n",
    "    train_data = SliceData(\n",
    "        root=data_path / 'singlecoil_train',\n",
    "        transform=DataTransform(train_mask, resolution, challenge),\n",
    "        sample_rate=sample_rate,\n",
    "        challenge=challenge\n",
    "    )\n",
    "    dev_data = SliceData(\n",
    "        root=data_path / 'singlecoil_val',\n",
    "        transform=DataTransform(dev_mask, resolution, challenge, use_seed=True),\n",
    "        sample_rate=sample_rate,\n",
    "        challenge=challenge,\n",
    "    )\n",
    "    return dev_data, train_data\n",
    "\n",
    "\n",
    "def create_data_loaders(data_path, batch_size=16):\n",
    "    dev_data, train_data = create_datasets(data_path)\n",
    "    display_data = [dev_data[i] for i in range(0, len(dev_data), len(dev_data) // 16)]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dev_loader = DataLoader(\n",
    "        dataset=dev_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    display_loader = DataLoader(\n",
    "        dataset=display_data,\n",
    "        batch_size=16,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, dev_loader, display_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device, num_channels=32, num_pools=4, dropout_prob=0.0):\n",
    "    model = UnetModel(\n",
    "        in_chans=1,\n",
    "        out_chans=1,\n",
    "        chans=num_channels,\n",
    "        num_pool_layers=num_pools,\n",
    "        drop_prob=dropout_prob\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "def build_optim(params, lr=0.001, weight_decay=0.):\n",
    "    optimizer = torch.optim.RMSprop(params, lr, weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(epoch, num_epochs, model, device, data_loader, optimizer, writer, report_interval=100):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    start_epoch = start_iter = time.perf_counter()\n",
    "    global_step = epoch * len(data_loader)\n",
    "    for iter, data in enumerate(data_loader):\n",
    "        input, target, mean, std, norm = data\n",
    "        input = input.unsqueeze(1).to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(input).squeeze(1)\n",
    "        loss = F.l1_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        writer.add_scalar('TrainLoss', loss.item(), global_step + iter)\n",
    "\n",
    "        if iter % report_interval == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{num_epochs:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(data_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g} '\n",
    "                f'Time = {time.perf_counter() - start_iter:.4f}s',\n",
    "            )\n",
    "        start_iter = time.perf_counter()\n",
    "    return avg_loss, time.perf_counter() - start_epoch\n",
    "\n",
    "\n",
    "def evaluate(epoch, model, device, data_loader, writer):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            input, target, mean, std, norm = data\n",
    "            input = input.unsqueeze(1).to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input).squeeze(1)\n",
    "\n",
    "            mean = mean.unsqueeze(1).unsqueeze(2).to(device)\n",
    "            std = std.unsqueeze(1).unsqueeze(2).to(device)\n",
    "            target = target * std + mean\n",
    "            output = output * std + mean\n",
    "\n",
    "            norm = norm.unsqueeze(1).unsqueeze(2).to(device)\n",
    "            loss = F.mse_loss(output / norm, target / norm, size_average=False)\n",
    "            losses.append(loss.item())\n",
    "        writer.add_scalar('Dev_Loss', np.mean(losses), epoch)\n",
    "    return np.mean(losses), time.perf_counter() - start\n",
    "\n",
    "\n",
    "def visualize(epoch, model, device, data_loader, writer):\n",
    "    def save_image(image, tag):\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "        grid = torchvision.utils.make_grid(image, nrow=4, pad_value=1)\n",
    "        writer.add_image(tag, grid, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            input, target, mean, std, norm = data\n",
    "            input = input.unsqueeze(1).to(device)\n",
    "            target = target.unsqueeze(1).to(device)\n",
    "            output = model(input)\n",
    "            save_image(target, 'Target')\n",
    "            save_image(output, 'Reconstruction')\n",
    "            save_image(torch.abs(target - output), 'Error')\n",
    "            break\n",
    "\n",
    "            \n",
    "def save_model(exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best):\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_dev_loss': best_dev_loss,\n",
    "            'exp_dir': exp_dir\n",
    "        },\n",
    "        f=exp_dir / 'model.pt'\n",
    "    )\n",
    "    if is_new_best:\n",
    "        shutil.copyfile(exp_dir / 'model.pt', exp_dir / 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘unet/summary’: File exists\n",
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "W0307 00:16:00.550040 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1000 expired tensor events from Tensorboard display between the previous step: 51381 (timestamp: 1583430061.852064) and current step: 0 (timestamp: 1583453025.966422).\n",
      "W0307 00:16:00.572877 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 174 expired tensor events from Tensorboard display between the previous step: 173 (timestamp: 1583453205.461077) and current step: 0 (timestamp: 1583453996.433022).\n",
      "W0307 00:16:00.687378 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 853 expired tensor events from Tensorboard display between the previous step: 852 (timestamp: 1583454132.1375165) and current step: 0 (timestamp: 1583455375.6992211).\n",
      "W0307 00:16:00.968151 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 23 expired tensor events from Tensorboard display between the previous step: 2171 (timestamp: 1583455723.7164176) and current step: 0 (timestamp: 1583455784.5954883).\n",
      "W0307 00:16:12.696326 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1000 expired tensor events from Tensorboard display between the previous step: 14911 (timestamp: 1583457967.7833145) and current step: 0 (timestamp: 1583520603.2741983).\n",
      "W0307 00:16:12.708430 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 4 expired tensor events from Tensorboard display between the previous step: 3 (timestamp: 1583520603.7638454) and current step: 0 (timestamp: 1583533388.3349764).\n",
      "W0307 00:16:12.981073 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1000 expired tensor events from Tensorboard display between the previous step: 2100 (timestamp: 1583533724.5700629) and current step: 0 (timestamp: 1583533729.9022455).\n",
      "W0307 00:16:13.261627 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 6 expired tensor events from Tensorboard display between the previous step: 2171 (timestamp: 1583534077.6800067) and current step: 0 (timestamp: 1583534138.6319535).\n",
      "W0307 00:16:13.551931 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1 expired tensor events from Tensorboard display between the previous step: 2171 (timestamp: 1583534529.3085675) and current step: 0 (timestamp: 1583534548.5690622).\n",
      "W0307 00:16:15.508061 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1 expired tensor events from Tensorboard display between the previous step: 2171 (timestamp: 1583535605.1329007) and current step: 0 (timestamp: 1583535624.3610504).\n",
      "W0307 00:16:21.370300 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 1000 expired tensor events from Tensorboard display between the previous step: 8687 (timestamp: 1583536719.871997) and current step: 0 (timestamp: 1583536733.8030245).\n",
      "W0307 00:16:21.651998 139813137123072 plugin_event_accumulator.py:588] Detected out of order event.step likely caused by a TensorFlow restart. Purging 3 expired tensor events from Tensorboard display between the previous step: 2171 (timestamp: 1583537081.7858417) and current step: 0 (timestamp: 1583537101.0016398).\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! mkdir unet/summary\n",
    "! tensorboard --logdir=unet/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:UnetModel(\n",
      "  (down_sample_layers): ModuleList(\n",
      "    (0): ConvBlock(in_chans=1, out_chans=32, drop_prob=0.0)\n",
      "    (1): ConvBlock(in_chans=32, out_chans=64, drop_prob=0.0)\n",
      "    (2): ConvBlock(in_chans=64, out_chans=128, drop_prob=0.0)\n",
      "    (3): ConvBlock(in_chans=128, out_chans=256, drop_prob=0.0)\n",
      "  )\n",
      "  (conv): ConvBlock(in_chans=256, out_chans=256, drop_prob=0.0)\n",
      "  (up_sample_layers): ModuleList(\n",
      "    (0): ConvBlock(in_chans=512, out_chans=128, drop_prob=0.0)\n",
      "    (1): ConvBlock(in_chans=256, out_chans=64, drop_prob=0.0)\n",
      "    (2): ConvBlock(in_chans=128, out_chans=32, drop_prob=0.0)\n",
      "    (3): ConvBlock(in_chans=64, out_chans=32, drop_prob=0.0)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "INFO:root:RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "INFO:root:Epoch = [  0/  2] Iter = [   0/2172] Loss = 1.317 Avg Loss = 1.317 Time = 0.7847s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 100/2172] Loss = 0.3903 Avg Loss = 0.7589 Time = 0.1592s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 200/2172] Loss = 0.5096 Avg Loss = 0.5289 Time = 0.1591s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 300/2172] Loss = 0.3609 Avg Loss = 0.4396 Time = 0.1607s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 400/2172] Loss = 0.2961 Avg Loss = 0.3915 Time = 0.1604s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 500/2172] Loss = 0.417 Avg Loss = 0.3763 Time = 0.1600s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 600/2172] Loss = 0.2913 Avg Loss = 0.3735 Time = 0.1599s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 700/2172] Loss = 0.4006 Avg Loss = 0.364 Time = 0.1592s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 800/2172] Loss = 0.351 Avg Loss = 0.361 Time = 0.1607s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [ 900/2172] Loss = 0.2654 Avg Loss = 0.3529 Time = 0.1593s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1000/2172] Loss = 0.2627 Avg Loss = 0.3546 Time = 0.1601s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1100/2172] Loss = 0.2478 Avg Loss = 0.3549 Time = 0.1592s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1200/2172] Loss = 0.4239 Avg Loss = 0.3594 Time = 0.1597s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1300/2172] Loss = 0.3584 Avg Loss = 0.3543 Time = 0.1593s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1400/2172] Loss = 0.499 Avg Loss = 0.356 Time = 0.1612s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1500/2172] Loss = 0.3304 Avg Loss = 0.3587 Time = 0.1597s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1600/2172] Loss = 0.3326 Avg Loss = 0.3478 Time = 0.1610s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1700/2172] Loss = 0.2529 Avg Loss = 0.3481 Time = 0.1601s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1800/2172] Loss = 0.3365 Avg Loss = 0.3396 Time = 0.1597s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [1900/2172] Loss = 0.3226 Avg Loss = 0.3515 Time = 0.1603s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [2000/2172] Loss = 0.4313 Avg Loss = 0.3548 Time = 0.1607s\n",
      "INFO:root:Epoch = [  0/  2] Iter = [2100/2172] Loss = 0.2676 Avg Loss = 0.3499 Time = 0.1600s\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "INFO:root:Epoch = [   0/   2] TrainLoss = 0.3476 DevLoss = 0.02301 TrainTime = 348.0329s DevTime = 19.1285s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [   0/2172] Loss = 0.2904 Avg Loss = 0.2904 Time = 0.7096s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 100/2172] Loss = 0.2971 Avg Loss = 0.3268 Time = 0.1593s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 200/2172] Loss = 0.3059 Avg Loss = 0.3328 Time = 0.1593s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 300/2172] Loss = 0.3316 Avg Loss = 0.3368 Time = 0.1604s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 400/2172] Loss = 0.3095 Avg Loss = 0.3396 Time = 0.1606s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 500/2172] Loss = 0.2374 Avg Loss = 0.3368 Time = 0.1599s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 600/2172] Loss = 0.3083 Avg Loss = 0.3344 Time = 0.1602s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 700/2172] Loss = 0.3851 Avg Loss = 0.3395 Time = 0.1606s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 800/2172] Loss = 0.3277 Avg Loss = 0.3355 Time = 0.1599s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [ 900/2172] Loss = 0.3561 Avg Loss = 0.3344 Time = 0.1608s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1000/2172] Loss = 0.3814 Avg Loss = 0.3326 Time = 0.1595s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1100/2172] Loss = 0.3108 Avg Loss = 0.3334 Time = 0.1600s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1200/2172] Loss = 0.3472 Avg Loss = 0.3387 Time = 0.1603s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1300/2172] Loss = 0.3243 Avg Loss = 0.3324 Time = 0.1604s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1400/2172] Loss = 0.3178 Avg Loss = 0.3364 Time = 0.1601s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1500/2172] Loss = 0.2488 Avg Loss = 0.3286 Time = 0.1598s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1600/2172] Loss = 0.3446 Avg Loss = 0.3283 Time = 0.1602s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1700/2172] Loss = 0.3019 Avg Loss = 0.328 Time = 0.1604s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1800/2172] Loss = 0.4783 Avg Loss = 0.3247 Time = 0.1598s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [1900/2172] Loss = 0.2809 Avg Loss = 0.3227 Time = 0.1607s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [2000/2172] Loss = 0.3114 Avg Loss = 0.3306 Time = 0.1597s\n",
      "INFO:root:Epoch = [  1/  2] Iter = [2100/2172] Loss = 0.3114 Avg Loss = 0.3285 Time = 0.1610s\n",
      "INFO:root:Epoch = [   1/   2] TrainLoss = 0.3296 DevLoss = 0.02105 TrainTime = 348.9248s DevTime = 19.1261s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def main(num_epochs=50):\n",
    "    device = torch.device('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')        \n",
    "        \n",
    "    outdir = Path('unet')\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    log_dir = outdir / 'summary'\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    model = build_model(device)\n",
    "    optimizer = build_optim(model.parameters())\n",
    "    best_dev_loss = 1e9\n",
    "    start_epoch = 0\n",
    "    logging.info(model)\n",
    "    logging.info(optimizer)\n",
    "\n",
    "    train_loader, dev_loader, display_loader = create_data_loaders(Path('../data'))\n",
    "    \n",
    "    lr_step_size = 40\n",
    "    lr_gamma = 0.1\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step_size, lr_gamma)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loss, train_time = train_epoch(epoch, num_epochs, model, device, train_loader, optimizer, writer)\n",
    "        dev_loss, dev_time = evaluate(epoch, model, device, dev_loader, writer)\n",
    "        visualize(epoch, model, device, display_loader, writer)\n",
    "\n",
    "        is_new_best = dev_loss < best_dev_loss\n",
    "        best_dev_loss = min(best_dev_loss, dev_loss)\n",
    "        save_model(outdir, epoch, model, optimizer, best_dev_loss, is_new_best)\n",
    "        logging.info(\n",
    "            f'Epoch = [{epoch:4d}/{num_epochs:4d}] TrainLoss = {train_loss:.4g} '\n",
    "            f'DevLoss = {dev_loss:.4g} TrainTime = {train_time:.4f}s DevTime = {dev_time:.4f}s',\n",
    "        )\n",
    "        scheduler.step(epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    \n",
    "main(num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
